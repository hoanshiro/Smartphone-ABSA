{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06098efd-425b-429e-8912-180d1fc60835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06098efd-425b-429e-8912-180d1fc60835",
    "outputId": "7f45ff1d-973b-4f4e-9a12-ef359bdbd501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 13 00:35:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4oydC3D8rQsS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oydC3D8rQsS",
    "outputId": "39d51e1d-ca27-4229-bfd1-d73f7f9a8f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Smartphone-ABSA' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hoanshiro/Smartphone-ABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1-HAoc-rT8Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1-HAoc-rT8Y",
    "outputId": "52fc16e8-fb26-4a85-a832-5ba993b4af3a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "base_path = '/home/henry/Desktop/'\n",
    "os.chdir(base_path + \"Smartphone-ABSA/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc541-cec0-4151-ba08-ec788ba89798",
   "metadata": {
    "id": "eb9cc541-cec0-4151-ba08-ec788ba89798"
   },
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4da8c-7e99-4ad9-99e8-19e63ab7af9b",
   "metadata": {},
   "source": [
    "### 1.1 Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30aaf24-4bd3-4018-aad8-f1ea4fd9c7be",
   "metadata": {
    "id": "c30aaf24-4bd3-4018-aad8-f1ea4fd9c7be"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b06a4-405d-49bf-9328-0aa88471af20",
   "metadata": {
    "id": "120b06a4-405d-49bf-9328-0aa88471af20"
   },
   "source": [
    "### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945a6679-ae0f-4e68-b89a-ab4c92234b98",
   "metadata": {
    "id": "945a6679-ae0f-4e68-b89a-ab4c92234b98"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/processed_data/processed_train.csv')\n",
    "df_valid = pd.read_csv('data/processed_data/processed_valid.csv')\n",
    "df_test = pd.read_csv('data/processed_data/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5d0a47-ac9d-4d30-b1a3-ccee35c9828c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "2a5d0a47-ac9d-4d30-b1a3-ccee35c9828c",
    "outputId": "e13264e3-bf2e-48a8-bb1f-826651b17fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenize</th>\n",
       "      <th>SCREEN#Positive</th>\n",
       "      <th>SCREEN#Neutral</th>\n",
       "      <th>SCREEN#Negative</th>\n",
       "      <th>CAMERA#Positive</th>\n",
       "      <th>CAMERA#Neutral</th>\n",
       "      <th>CAMERA#Negative</th>\n",
       "      <th>FEATURES#Positive</th>\n",
       "      <th>FEATURES#Neutral</th>\n",
       "      <th>FEATURES#Negative</th>\n",
       "      <th>...</th>\n",
       "      <th>DESIGN#Negative</th>\n",
       "      <th>PRICE#Positive</th>\n",
       "      <th>PRICE#Neutral</th>\n",
       "      <th>PRICE#Negative</th>\n",
       "      <th>GENERAL#Positive</th>\n",
       "      <th>GENERAL#Neutral</th>\n",
       "      <th>GENERAL#Negative</th>\n",
       "      <th>SER&amp;ACC#Positive</th>\n",
       "      <th>SER&amp;ACC#Neutral</th>\n",
       "      <th>SER&amp;ACC#Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>8g cái đi đánh là mạng giật giật ko chịu nổi c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>mua dk giảm 500k mà lỗi lòi ra hết treo màn_hì...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>máy sài 3 tháng rồi rất ok pin trâu khỏi nói s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>rất tiếc hàng realme ko có ốp lưng ngoài nên k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>mình rất thất_vọng khi mua máy này bắt wifi cự...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tokenize  SCREEN#Positive  \\\n",
       "7781  8g cái đi đánh là mạng giật giật ko chịu nổi c...                0   \n",
       "7782  mua dk giảm 500k mà lỗi lòi ra hết treo màn_hì...                0   \n",
       "7783  máy sài 3 tháng rồi rất ok pin trâu khỏi nói s...                0   \n",
       "7784  rất tiếc hàng realme ko có ốp lưng ngoài nên k...                0   \n",
       "7785  mình rất thất_vọng khi mua máy này bắt wifi cự...                0   \n",
       "\n",
       "      SCREEN#Neutral  SCREEN#Negative  CAMERA#Positive  CAMERA#Neutral  \\\n",
       "7781               0                0                0               0   \n",
       "7782               0                0                0               0   \n",
       "7783               0                0                0               0   \n",
       "7784               0                0                0               0   \n",
       "7785               0                0                0               0   \n",
       "\n",
       "      CAMERA#Negative  FEATURES#Positive  FEATURES#Neutral  FEATURES#Negative  \\\n",
       "7781                0                  0                 0                  1   \n",
       "7782                0                  0                 0                  1   \n",
       "7783                0                  0                 0                  0   \n",
       "7784                0                  0                 0                  0   \n",
       "7785                0                  0                 0                  1   \n",
       "\n",
       "      ...  DESIGN#Negative  PRICE#Positive  PRICE#Neutral  PRICE#Negative  \\\n",
       "7781  ...                0               0              0               0   \n",
       "7782  ...                0               1              0               0   \n",
       "7783  ...                0               0              0               0   \n",
       "7784  ...                0               0              0               1   \n",
       "7785  ...                0               0              0               0   \n",
       "\n",
       "      GENERAL#Positive  GENERAL#Neutral  GENERAL#Negative  SER&ACC#Positive  \\\n",
       "7781                 0                0                 0                 0   \n",
       "7782                 0                0                 0                 0   \n",
       "7783                 1                0                 0                 0   \n",
       "7784                 1                0                 0                 0   \n",
       "7785                 0                0                 1                 0   \n",
       "\n",
       "      SER&ACC#Neutral  SER&ACC#Negative  \n",
       "7781                0                 0  \n",
       "7782                0                 0  \n",
       "7783                0                 0  \n",
       "7784                0                 1  \n",
       "7785                0                 1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df5a30-38a9-42e1-bcbe-8c4381c2b4db",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c499781-e2eb-400f-b076-0d6a691fa2cc",
   "metadata": {
    "id": "0c499781-e2eb-400f-b076-0d6a691fa2cc"
   },
   "source": [
    "### 2.1 Select Max Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26b7da4-09e6-433d-9f95-a54def0ac8fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c26b7da4-09e6-433d-9f95-a54def0ac8fc",
    "outputId": "e488379a-06ce-4f11-a35a-78f8eff5c2b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542aa41cef27460e9314b24c9568f1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9d03a733354dfd81c5d6cbf5929e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa105acd3cd4d4abca8b2fd6f527a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868dcc17-18c6-4f4e-9fcd-1768ad919091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "868dcc17-18c6-4f4e-9fcd-1768ad919091",
    "outputId": "9559ee06-57d3-4a79-ca3e-c8f9ffd55ca1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                          | 0/7786 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7786/7786 [00:01<00:00, 5355.40it/s]\n",
      "/home/henry/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApUklEQVR4nO3deXzcd33n8ddnRqP7vizZsizfV0wSx4njJAXKEeIEcEspJOEu3ZACjwWWbhtKt8futmUpSymUJgSaQrgCS5LWQEgISSAB4hA7h+P7kG1Zlmydti7rGM1n/5iRo4ixLcsazaH38/GYhzS/Q/O2Jc1Hv+/ve5i7IyIiMlEg2QFERCQ1qUCIiEhcKhAiIhKXCoSIiMSlAiEiInFlJTvAdKqsrPSGhoZkxxARSRvbtm3rcPeqePsyqkA0NDSwdevWZMcQEUkbZnbkbPvUxCQiInGpQIiISFwJLRBmdoOZ7TWzA2Z2R5z9ZmZfjO3fbmZrx+07bGYvmdkLZqZ2IxGRGZawexBmFgS+DLwRaAaeNbPN7r5r3GEbgaWxx3rgztjHMb/r7h2JyigiImeXyCuIq4AD7t7o7sPAfcCmCcdsAu71qC1AqZnVJjCTiIhMUiILxDzg6LjnzbFtkz3GgZ+a2TYzuy1hKUVEJK5EdnO1ONsmTh17rmOudfcWM6sGHjWzPe7+5G+9SLR43AZQX19/MXlFRGScRF5BNAPzxz2vA1ome4y7j31sAx4k2mT1W9z9bndf5+7rqqrijvUQEZEpSGSBeBZYamYLzSwbuBnYPOGYzcB7Y72ZrgZOuXurmRWYWRGAmRUA1wM7EphVREQmSFgTk7uHzeyjwCNAELjH3Xea2e2x/XcBDwE3AgeAAeADsdPnAA+a2VjG77j7w4nKOtt955mm39p263o114nMdgmdasPdHyJaBMZvu2vc5w58JM55jcClicwmIiLnppHUIiISlwqEiIjEpQIhIiJxqUCIiEhcKhAiIhKXCoSIiMSlAiEiInGpQIiISFwqECIiEpcKhIiIxKUCISIicalAiIhIXCoQIiISlwqEiIjEpQIhIiJxqUCIiEhcKhAiIhKXCoSIiMSlAiEiInGpQIiISFwqECIiEpcKhIiIxKUCISIicalAiIhIXCoQIiISlwqEiIjEpQIhIiJxqUCIiEhcKhAiIhKXCoSIiMSlAiEiInGpQIiISFwqECIiEpcKhIiIxJXQAmFmN5jZXjM7YGZ3xNlvZvbF2P7tZrZ2wv6gmT1vZj9KZE4REfltCSsQZhYEvgxsBFYBt5jZqgmHbQSWxh63AXdO2P8xYHeiMoqIyNkl8griKuCAuze6+zBwH7BpwjGbgHs9agtQama1AGZWB9wEfC2BGUVE5CwSWSDmAUfHPW+ObZvsMV8A/gyInOtFzOw2M9tqZlvb29svKrCIiLwskQXC4mzzyRxjZm8G2tx92/lexN3vdvd17r6uqqpqKjlFRCSORBaIZmD+uOd1QMskj7kWeKuZHSbaNPU6M/tW4qKKiMhEiSwQzwJLzWyhmWUDNwObJxyzGXhvrDfT1cApd29190+5e527N8TOe9zd353ArCIiMkFWor6wu4fN7KPAI0AQuMfdd5rZ7bH9dwEPATcCB4AB4AOJyiMiIhcmYQUCwN0fIloExm+7a9znDnzkPF/j58DPExBPLtB3nmmKu/3W9fUznEREZoJGUouISFwqECIiEpcKhIiIxKUCISIicalAiIhIXCoQIiISlwqEiIjEpQIhIiJxqUDIGX1DYSI+cT5FEZmtEjqSWtLDwHCYH29v5fmjJynLD/G7y6s1OlpEdAUx27k79z59hBebT7JhUQWFOVk88PwxfrbrRLKjiUiSqUDMco/sPEFT1wCbLp3HWy6dyx//ziLmlubyie+/wNGugWTHE5EkUoGYxcKjET77yB6qinJYu6AMgFAwwK1XLWBkNMI/PbovyQlFJJlUIGaxx/a00djezxtXziEYeHlxv/KCbN5z9QL+44VjNLb3JTGhiCSTCsQs9vCO45Tmh1hZW/xb+2579WKyswJ86fEDSUgmIqlABWKWGg5H+NnuE7xhwtXDmKqiHG65qp4fvthCe+9QEhKKSLKpQMxSTzd20jsY5obVNWc95l3r6wlHnB9sa57BZCKSKlQgZqmHdxwnPzvIdUsrz3rMkuoirmwo43vPNuEaQCcy66hAzFJP7W/nd5ZWkhsKnvO4m6+s53DnAE83ds5QMhFJFSoQs9CJnkGau09zZUP5eY+9cU0tBdlB/vP5lhlIJiKpRAViFtp2pBuAdZMoEHnZQa5fXcNPdrQSjkQSHU1EUogKxCy09XA3OVkBVsXp3hrPWy6tpWcwzIE2jYkQmU1UIGahbU3dXDq/lOysyX37r1tSRUleiO3NpxKcTERSiQrELPP1Xx3mpeaT5IWCfOeZJr7zTNN5z8nOCrDxkhp2tfYQHlUzk8hsoQIxyxw7eZqIw4Ly/As6702raxgOR2js6E9QMhFJNSoQs0zLydMAzCvLu6DzNiyuIDsYYFdrTyJiiUgKUoGYZY73DFKQk0VRbuiCzssNBVk6p5A9rT1adU5kllCBmGWOnxqktjh3SueurC2mZzB85ipERDKbCsQsEh6NcKJnkJqSqRWIFXOKCBhqZhKZJVQgZpHDnQOEIz7lApGfk8WCigJ2q0CIzAoqELPInuPRN/aaKTYxQbSZ6UTPEF39w9MVS0RSlArELLK7tYeAQXVRzpS/xsqaojNfS0QymwrELLKntZfKwhyyglP/tlcU5lBdlKP7ECKzQFYiv7iZ3QD8MxAEvubun5mw32L7bwQGgPe7+3Nmlgs8CeTEMv7A3f86kVkzTbwR0s81dTP/AgfIxbOqtpgn97czMBwmPzuhP0IikkQJu4IwsyDwZWAjsAq4xcxWTThsI7A09rgNuDO2fQh4nbtfClwG3GBmVycq62wwMhrh5MAIVYVTb14as6K2mIjD/hOavE8kkyWyiekq4IC7N7r7MHAfsGnCMZuAez1qC1BqZrWx52PvPqHYQ6OzLkJH3xAOVF7E/YcxdWV5FGQHz9z0FpHMlMgCMQ84Ou55c2zbpI4xs6CZvQC0AY+6+zPxXsTMbjOzrWa2tb29fbqyZ5yOvmivo+m4ggiYsbymiH0n+hiNqG6LZKpJFQgzu9/MbjKzCykoFmfbxHeTsx7j7qPufhlQB1xlZpfEexF3v9vd17n7uqqqqguIN7u09w4BUDkNBQJgRU0xp0dGaeoamJavJyKpZ7Jv+HcCtwL7zewzZrZiEuc0A/PHPa8DJq5bed5j3P0k8HPghklmlTg6+oYoyQtNeg2I81lSXUjQTM1MIhlsUu8W7v4zd38XsBY4DDxqZr82sw+Y2dlmfXsWWGpmC80sG7gZ2DzhmM3Aey3qauCUu7eaWZWZlQKYWR7wBmDPhf7j5GXtvUPT0rw0JjcUZGFlAXuO907b1xSR1DLpPyfNrAJ4P/DHwPNEu6euBR6Nd7y7h4GPAo8Au4Hvu/tOM7vdzG6PHfYQ0AgcAL4KfDi2vRZ4wsy2Ey00j7r7jy7snyZj3J2OvqFpuUE93vKaItp7hzjSqTUiRDLRpDqxm9kDwArgm8Bb3L01tut7Zrb1bOe5+0NEi8D4bXeN+9yBj8Q5bztw+WSyyfn1DoUZCkeoKsye1q+7oqaIH7/UyuN72vjAtQun9WuLSPJN9gria+6+yt3/Yaw4mFkOgLuvS1g6mRZnblBP8xVERWEOVYU5PL6nbVq/roikhskOg/3fTLgSAJ4m2sQkKa4z1sX1QnowTWataoheRWxp7KRvKExhjkZVi2SSc15BmFmNmV0B5JnZ5Wa2NvZ4LXDxczbIjOjsHyIYMEryLmwVuclYUVvMyKjz1D6NQRHJNOf7k+9NRG9M1wGfH7e9F/iLBGWSadbVP0x5fjYBizfs5OLUl+dTnJvFY3va2Limdtq/vogkzzkLhLt/A/iGmf2Bu98/Q5lkmnX1D1NeML03qMcEA8Zrl1fzxJ42IhEnEJj+IiQiyXHOAmFm73b3bwENZvbfJu5398/HOU1SiLvT2TdMQ2VBwl7j9Sur2fxiCy82n+Ty+rKEvY6IzKzz9WIae1cpBIriPCTF9Q2FGR6NUJGgKwiA1yyrImCoN5NIhjlfE9NXYh//dmbiyHQbWxo0kQWiND+bdQvKeWx3G5+8fnnCXkdEZtZkJ+v7rJkVm1nIzB4zsw4ze3eiw8nFGysQ5QXTOwZiotetrGZXaw+tp04n9HVEZOZMdqDc9e7eA7yZ6AR7y4D/nrBUMm06+4cxoCx/+ru4jveGldWAmplEMslkRzaNvbvcCHzX3bssAV0mZfp19Q9Tkhe6qHWoJ2NxVSH15fk8truNd61fEHeg3a3r6xOaQUSm12TfNX5oZnuAdcBjZlYFDCYulkyXzr4hyqd5DqZ4zIzXrajmVwc6OD08mvDXE5HEm+x033cAG4B17j4C9PPby4dKChobJDcT3rByDkPhCE/u16hqkUxwIZPnrCQ6HmL8OfdOcx6ZRkPhUfqHRxM2SG6i9YvKKckL8cjO46xbUD4jrykiiTPZ6b6/CSwGXgDG2g8cFYiU1j0wAkDZDBWIUDDA61dU89juNi6fX0ZQo6pF0tpkryDWAati6zdImuiOdXEtm6EmJoDrV9fwwPPHONTRz5Lqwhl7XRGZfpO9Sb0DqElkEJl+3QNjBSKxXVzHe82yKnJDAXa1npqx1xSRxJhsgagEdpnZI2a2eeyRyGBy8br7hwkFbUbXacjLDvKaZVXsaukhogtOkbQ22XeOv0lkCEmM7oERyvKzmekxK29aXcMjO09wrPs088u1bIhIuppsN9dfAIeBUOzzZ4HnEphLpkH3wPCM3n8Y8/oVcwgY7GzpmfHXFpHpM9m5mP4L8APgK7FN84D/SFAmmQbuTlf/8Iz1YBqvJD/EospCdrWeQv0aRNLXZO9BfAS4FugBcPf9QHWiQsnFOz0yylA4QvkM3qAeb9XcYjr6hjnRO5SU1xeRizfZAjHk7sNjT2KD5fSnYQrr7o+OgShNQhMTwOq5xRjwUrN6M4mkq8kWiF+Y2V8AeWb2RuD/AT9MXCy5WF0DY9N8J6dAFOWGWFhVwEvHTqqZSSRNTbZA3AG0Ay8BHwIeAv4yUaHk4iVjkNxEl84rpaNvmNZTmtdRJB1NthdThOhN6Q+7+9vd/asaVZ3augeGyQ0FyMsOJi3D6rnFBAy2q5lJJC2ds0BY1N+YWQewB9hrZu1m9lczE0+mqntg5mZxPZv8nCyWVBeqmUkkTZ3vCuLjRHsvXenuFe5eDqwHrjWzTyQ6nExdd/9IUrq4TvSqulK6B0Zo7tZSpCLp5nwF4r3ALe5+aGyDuzcC747tkxTk7kkbJDfRqtpiggFje/PJZEcRkQt0vgIRcveOiRvdvZ2XlyGVFNPeO0Q44ilxBZEbCrJ8ThEvHTtFJKJmJpF0cr4CMTzFfZJER7sHgJmdxfVc1tSV0DMY5plDXcmOIiIX4HyT9V1qZvEm1DEgNwF5ZBoc7Yq296dCExPAyppicrICPPBcMxsWVyQ7johM0jkLhLsnr4+kTFnzmSuImSkQ33mm6Zz7s7MCrJlXwkMvtfK3m1aTnz1z04+LyNRNdqDclJjZDWa218wOmNkdcfabmX0xtn+7ma2NbZ9vZk+Y2W4z22lmH0tkzkxztOs0hTlZZGcl9Nt7QS6vL6N/eJSHdxxPdhQRmaSEvYOYWRD4MrARWAXcYmarJhy2EVgae9wG3BnbHgY+6e4rgauBj8Q5V87iaPdAytx/GNNQkU99eT73P9ec7CgiMkmJ/BPzKuCAuzfGJvq7D9g04ZhNwL0etQUoNbNad2919+cA3L0X2E10inGZhKPdAynRg2k8M+Nta+fx64OdHDupMREi6SCRBWIecHTc82Z++03+vMeYWQNwOfBMvBcxs9vMbKuZbW1vb7/YzGkvPBqh9eRg0kdRx/MHa+twhwd1FSGSFhJZIOKtczmxI/w5jzGzQuB+4OPuHnd5Mne/293Xufu6qqqqKYfNFK2nBglHPGmzuJ7L/PJ81i8s5/7njmnqDZE0kMgC0QzMH/e8DmiZ7DFmFiJaHL7t7g8kMGdGaeqK9WBKwQIB8AdX1HGoo59tR7qTHUVEziOR/Q2fBZaa2ULgGHAzcOuEYzYDHzWz+4jO8XTK3VvNzIB/A3a7++cTmDHjjBWIVLyCALhpTS3/84e7+O5vjrKuofysXWRvXV8/w8lEZKKEXUG4exj4KPAI0ZvM33f3nWZ2u5ndHjvsIaAROAB8FfhwbPu1wHuA15nZC7HHjYnKmkmaugbIChgleanVi2lMQU4Wv3f5XH60vYWTAxqML5LKEjpiyd0fIloExm+7a9znTnS964nn/ZL49yfkPJq6BqgryyNgqfvfd+tVC/jWlibuf+4YeSGNxRRJVakzkkqmxdGuAeaX5yc7xjmtmlvM2vpSvv3MEd2sFklhKhAZpqlrgPoULxAA71q/gMb2fg519Cc7ioichQpEBjl1eoSTAyNpUSBuelUtJXkhzfAqksJUIDLI0VgPpnQoELmhIG+/oo5dLT30Do4kO46IxKECkUHGCkSq34MYc+v6ekbdefawriJEUpEKRAYZGwNRX5EeBWJxVSHL5hTydGMXI6ORZMcRkQlUIDJIU9cApfkhinNTcwxEPNctqaJ/KMyLR08mO4qITKACkUHSpQfTeIurCqgtyeWXBzrU5VUkxahAZJB0GAMxkZlx3ZJK2nqH2HeiL9lxRGQcFYgMMRpxmrtPp90VBMCauhKKc7P45QFN1y6SSlQgMkTrqdOEI56WBSIrEGDD4koOtvfTosWERFKGCkSGaEqjMRDxXNVQTk5WgJ/vbUt2FBGJUYHIEOk0SC6evOwg1yyuYEdLD62ndBUhkgoSOpurzJymrgGCAaO2JDfZUc7qbGs/jLluSRW/PtjJY7vb+OT1y2colYicja4gMkRT12nmleaRFUzfb2ledpBrl1Syq7WHHcdOJTuOyKyXvu8m8grpOAYinmsXV5IbCvCFn+1LdhSRWU8FIkOk4xiIePKyg1y3pIqf7W7T6GqRJFOByAA9gyN09Q9nxBUEwDWLKyjLD/F3D+3W6GqRJFKByACH2qOL7iyqKkhykumRGwryp29azm8OdfGj7a3JjiMya6lAZICxVdkWVWZGgQC4+cp6VtUW8/cP7WZgOJzsOCKzkrq5ZoDGjn7M0mea78kIBoy/3bSaP7zrae78+UE+ef3yuN1kb11fn4R0IrODriAywOGOfurK8sjJCiY7yrS6sqGcTZfN5StPNtLUOZDsOCKzjgpEBjjU0U9DReY0L433qY0ryQoYf/mfO3TDWmSGqUCkOXfnUEd/Rt1/GK+mJJc/v2EFT+5rZ+uR7mTHEZlVVCDSXHvfEH1DYRZmaIEAeM/VC7h6UTkPvdRKV/9wsuOIzBoqEGlurIvrwqrCJCdJnEDA+Me3X4oZ3PdsE+GI1q8WmQkqEGkuE7u4xjO/PJ+3XV5Hc/dpfvLS8WTHEZkVVCDSXGNHP9nBAHNL85IdJeEumVfCtYsreLqxk6cbO5MdRyTjaRxEmtt/opdFVQUEA5bsKDNi45paOvuH+dGLLZTnh5IdRySjqUCkuf1tfVxeX5bsGDMmYMY7r5zPV59s5LvPHuWdV9azam7xK44527oTGlQncmHUxJTG+ofCNHefZll15t6gjicnK8h7NjSQmxXgvfc8w97jvcmOJJKRVCDS2MH2PgCWzpldBQKgJC/EB69bRMCMW766hV0tPcmOJJJx1MSUxvadGCsQRUlOMv3OtzwpQFVRDt/70AZu/eoWbv3aFr71wfVcMq9kBtKJzA4JvYIwsxvMbK+ZHTCzO+LsNzP7Ymz/djNbO27fPWbWZmY7Epkxne1v6yU7GGBBhqwDMRULKwv43m0bKMjO4ua7t/CrAx3JjiSSMRJWIMwsCHwZ2AisAm4xs1UTDtsILI09bgPuHLfv68ANicqXCfaf6GNRVUFar0M9Heor8vnBn2xgXmke7//33/CCVqITmRaJfGe5Cjjg7o3uPgzcB2yacMwm4F6P2gKUmlktgLs/CXQlMF/a29/Wm5HNS1NRW5LH92/fwNr6Mr6/9ShP7mvX5H4iFymRBWIecHTc8+bYtgs95pzM7DYz22pmW9vb26cUNB0NDIc52nWapbOsB9O5lOSFuPeDV7FmXgkP7zzOj7a3ElGREJmyRBaIeCO3Jv62TuaYc3L3u919nbuvq6qqupBT09ru1mjXzhU1uoIYLycryDuvnM91Syp5urGT7/6miZFRzd0kMhWJLBDNwPxxz+uAlikcI3HsajkFwGr12vktATNuXFPLTWtq2dXSwz2/OqRlS0WmIJEF4llgqZktNLNs4GZg84RjNgPvjfVmuho45e5apX4SdrX2UJofYm5JbrKjpKxrl1Tyzivn09x9mq882Uhzt1alE7kQCRsH4e5hM/so8AgQBO5x951mdnts/13AQ8CNwAFgAPjA2Plm9l3gtUClmTUDf+3u/5aovOlmZ0sPq+cWY2aTGjMwW72qrpTC3Cy+teUIb/vXX/PvH7iS1XNfvurSOtciZ5fQgXLu/hDRIjB+213jPnfgI2c595ZEZktnI6MR9hzv5X0bFiQ7SlpYVFnIh169mO9vPco7v7KFu959BdctrUx2LJGUN7s70Kepg+19DIcjr/hLWM5tTnEuD3z4GurKomMlHny+OdmRRFKeptpIQzuPRecdWj1hFtPZ6EKa18bGSnzo3m184nsv0npqkJLcEGazY6p0kQulK4g0tLOlh9xQgEUZvMxoohTnhvj6H13JWy+dy2cf3st/vNDCaERjJUTi0RVEGnrhaDdr5pXMmkWCpltOVpAvvPMy6sry+NefH+TkwDC3XFVPbiiY7GgiKUVXEGlmcGSUHcd6WDuLFglKhEDA+LMbVvD7l8/jYHsfdz/ZSGffULJjiaQUFYg0s7PlFMOjEdYuUIGYDlc2lPO+axo4dXqEf3niADtjAxBFRAUi7Ww70g2gK4hptLS6iI++bgmVhTl8+5km/u7HuxgKjyY7lkjSqUCkmeeOnKS+PJ+qopxkR8koZfnZfOjVi1i/sJyvPnWIm774S7Yd0WTCMrvpJnUacXe2NXVz3RIN8pqK83WJzQoG2HTZPP7ktYv59IM7ePtdT/OeqxfwiTcs4yc7jsc9R6OuJZPpCiKNNHUN0N47xNr60mRHyWivXV7NI594Ne/b0MA3txzh1Z99gsf3tKnZSWYdFYg08svYcprX6Aoi4Qpzsvibt67mkY+/mg2LK/jZ7hN87qf7+PneNs0MK7OGCkQaeWpfB/NK81hUWZDsKLPGsjlF3P3eddz+msXMK83lp7tO8NmH9/LD7S109w8nO55IQukeRJoIj0b41cEOblpTq6khkqC+PJ/3X7OQ46cGeWp/O880drLlYCe7jvfw/msaWLegTN8XyTgqEGli+7FT9A6GNQtpktWU5PKH6+Zz/eoafn2wg6f2tfPj7a2sqi3m/dc08NbL5mpEtmQMNTGliaf2dWAG1y5WgUgFJXkhNl5Sy5a/eD1///trGI04f3b/djb8w2N85id7tDiRZATzDFrUfd26db5169Zkx0iIt3zplwQDxjvWzT//wTLj3J1DHf083djJrpbobLsra4tZ11DG0uoi3qO1OyRFmdk2d18Xb5+amNLAkc5+Xjp2ik/fuDLZUeQszIxFVYUsqirk5MAwzxzq4tnDXexq7aEgO8jB9j5uXFPL2vpSsoLRC3etZiepTgUiDfz4pegy3RvX1PDkvo4kp5HzKc3P5k2ra3j9ymr2n+jj+aMn+c5vmvj6rw9Tmh/id5dX84aVcxgcGdX9CklpKhBp4MfbW7m8vpS6svxkR5ELkBUIsLK2mJW1xbzl0lqe2t/Bz3af4Ik9bTz4/DECBgsqClg+p4ilcwqpKc5NdmSRV1CBSHEH2/vY2dLDX96k5qV0VpQb4sY1tdy4ppbRiPNcUzdfeuwA+9t6eXjncR7eCcW5WbzYfJLXLq/m2iWVlOSFzpyv5ihJBhWIFPfNp48QChpvvWxusqPINAkGjCsbyrnhkhpuoIae0yPsb+tl74k+Ht5xnO9vbSYYMNbWl/KaZVW8dnk1EXcCGmchM0wFIoX1DYW5f1szN62ppbpIzQ/p7FwTBRbnhbhiQTlXLCjnHevqeOHoSX6xr52f723ncz/dx+d+uo/CnCyWVheybE4RS6oLKcjRr64knn7KUtiDzzXTOxTmfdc0JDuKzJCsYIB1DeWsayjnk9cvp6NviCf3tfONXx9m74lenj96EgPmleVx/NRpXr2sisvmq2eUJIYKRIoaCo9y91ONXDq/lMu1ONCsVVmYw9vW1jE4EiHiTsvJ0+w70cu+E338yxMH+OLjByjKzeLqRRVcvaiC7v5hakpy1Rwl00IFIkV9a0sTR7tO8/e/vybZUSRFBMyoK8unriyf162Yw01ravnVwQ6e3NfO042dPLrrBAB5oSALKwtYWFnAoqoCIhEnEFDBkAunApGCTg2M8KXH9/M7Syv5naVVyY4jM+h8ixqNV5L/cs8ogJaTp/mnR/fR2NHPoY5+drVGR3R/c8sR1i8sZ8OiCq5eXMGy6iIVDJkUFYgU9D/+cwe9g2Hu2Lgi2VEkjcwtzePy+rIzTZLdA8Mc6ugHYEtjJ4/sjF5hlBdks35hOesXlnNZfRkraoo0YC9B0v2ekApEinnw+WY2v9jCJ9+4jNVzS5IdR1LY+a42yvKzKavPPvOGdLRrgC2NnWxp7GJLY+eZZVQDBnOKc5lXmsebX1XLwqpCFlYUMLc0l6xgIO3f5GTqVCBSyNMHO7nj/pe4qqGcD//ukmTHkQwx8Q3+igVlrK0v5dTpEZq7T3PsZPSxs6WHrUe6zxwXChrzy/MJBQKUFWRTXpBNeX70Y/9QWF1tZwF9h1PErw92cNu926gvz+eu91xBUG3EkkBmRml+NqX52VwyL3ql6u68cdUcDnX0c7izn8OdAxzu6OfFoyc53NnPUDhy5vwvPr6fysIc6svzqC/Pp76igIWV+SyoKGBhRQGl+SEtoJQBVCCSLDwa4Z5fHeL/PLyXhZUFfPOD6ykvyAYu7IalyMUyM6qLc6kuzmX9oooz27/zTBPuzumRUbr6h+nqH6a+Ip+mzgGaugZ49nA3m19sITJu5YDcUIDKwhzKC7J5zbIqqotyqCzMoaIwh8rCbJ7Y005OKPCK7rhqtko9KhBJ4u78Yl87//jIXna29HD9qjn833dcSlFu6PwniyTI2f4oMTPys7PIz846M2lkaV02r6orBaJ/6HQNDNPVN0xH/zCdfUN09g9ztGuALz9x4BXF48zXBPKyg+SFguRnB3l013HK8rMpyQ9Rlp9NaX6I0vxsKmLNWxWF0SausUGB6SA8GqF7YITTI6OMRpysgNFy8jQ1xblp0ZNMBWIGuTt7T/Tyk5eO8+OXWjnQ1sfckly+fOtablxTo0tySVtZwQDVRblxp4R5x7o6ugaG6egdprN/iI6+IX62q42B4TADw6MMDI9yemSU9r4h9rf1cXJghL6h8FlfKy8UZG5pLhWFOVTECkdFQfRqpTgvi6KcEMV5IYpys2KPEEU5WQl7Q45EnNaeQQ6193Ooo+9MN+PG9n6Odg0wsTbe+YuDZGcFqC/P51XzSs4Mcpxfnpdy7wEJXVHOzG4A/hkIAl9z989M2G+x/TcCA8D73f25yZwbT6qtKNczOMLBtj62N5/i+aZutjV1c7TrNEZ0mucrFpRx6fwSsgLp8xeRyEwYjfgrCkjfUJj+2KNvKExFYTadfcN0xq5WTp4e4XxvZYU50YIxMuqEgkYoGCAraIQCAUJZAZbNKSQ3FCQ3K0hW8OU36vFv2UPhCH1DYfoGw3T2D9FycpATPYOEx10i5We/PFCxf2iUysJs8rOzCAaMcCTC8poimjoHaOzo5/mmbjr6hgGYV5rH+kXlXBWbamVxVcGMFIykrChnZkHgy8AbgWbgWTPb7O67xh22EVgae6wH7gTWT/LchHJ3RiNOxCFy5vPox/7h0TM/rP1Do3QPDHOiZ5C23iFO9AzSemqQwx39tPUOnfl61UU5XF5fytr6MlbVFqspSeQcggGL/uU/yd+T0Uj0Hsng8CiD4VEGRyIMjoxy6fwSegfD9AyG6R0coXcwzN7jvYyMRmIPZ3B4hJFRp7t/mKHYuaOxN/xw5OUb8+6QFTQqCnIozMmirCDE+oXl1JTkcuzkaaoKo/dZinKzzvnGPv5ei7tzoK2PLY2dPN3YyS/2tvPAc8cAKMsPsbymiGVzilhcVcic4lwqC7OpKMyhIDtITlaQnFCA7GAgYVdHiWxiugo44O6NAGZ2H7AJGP8mvwm416OXMVvMrNTMaoGGSZw7ba74X4/SNxTGHUZjRWAqcrICzCnOZU5xDq9ZVkXvYJjKwhzmluZSkqdeHSKJEgwYhTlZFE7oejsa4cy9k7EFmdYmYG6zqS7mZWYsnVPE0jlFvGdDA+5OY0c/zx7q4rmmbva39fHgc8foPUeTG0BNcS5b/uL1U8pwLoksEPOAo+OeNxO9SjjfMfMmeS4AZnYbcFvsaZ+Z7b2IzFNVCXQA7EvCi1+AMzlTXDrkTIeMoJzT7aJzvmuagox3BLBPv2LTheRccLYdiSwQ8f5cnvin+dmOmcy50Y3udwN3X1i06WVmW8/WhpdKlHP6pENGUM7pNttyJrJANAPzxz2vA1omeUz2JM4VEZEESmT3mWeBpWa20MyygZuBzROO2Qy816KuBk65e+skzxURkQRK2BWEu4fN7KPAI0S7qt7j7jvN7PbY/ruAh4h2cT1AtJvrB851bqKyToOkNnFdAOWcPumQEZRzus2qnAkdByEiIulLI7RERCQuFQgREYlLBeIimNkNZrbXzA6Y2R3JzjPGzOab2RNmttvMdprZx2Lby83sUTPbH/s4/SOGpsDMgmb2vJn9KPY85XLGBnH+wMz2xP5fN6Rozk/Evuc7zOy7ZpabCjnN7B4zazOzHeO2nTWXmX0q9nu118zelOSc/xj7vm83swfNrDQVc47b96dm5mZWebE5VSCmaNx0IBuBVcAtZrYquanOCAOfdPeVwNXAR2LZ7gAec/elwGOx56ngY8Ducc9TMec/Aw+7+wrgUqJ5Uyqnmc0D/iuwzt0vIdrB42ZSI+fXgRsmbIubK/azejOwOnbOv8Z+35KV81HgEnd/FdGxsJ9K0ZyY2XyiUxQ1jds25ZwqEFN3ZioRdx8GxqYDSTp3bx2b9NDde4m+mc0jmu8bscO+AfxeUgKOY2Z1wE3A18ZtTqmcZlYMvBr4NwB3H3b3k6RYzpgsIM/MsoB8ouOHkp7T3Z8EuiZsPluuTcB97j7k7oeI9nK8Klk53f2n7j4218UWouOyUi5nzD8Bf8YrBxZPOacKxNSdbZqQlGJmDcDlwDPAnNg4E2Ifq5MYbcwXiP5AR8ZtS7Wci4B24N9jTWFfM7MCUiynux8DPkf0r8dWouOKfkqK5RznbLlS+Xfrj4CfxD5PqZxm9lbgmLu/OGHXlHOqQEzdpKcDSRYzKwTuBz7u7j3JzjORmb0ZaHP3bcnOch5ZwFrgTne/HOgnNZq9XiHWhr8JWAjMBQrM7N3JTTUlKfm7ZWafJtp8++2xTXEOS0pOM8sHPg38VbzdcbZNKqcKxNRNZiqRpDGzENHi8G13fyC2+YRFZ8sl9rEtWflirgXeamaHiTbRvc7MvkXq5WwGmt39mdjzHxAtGKmW8w3AIXdvd/cR4AHgGlIv55iz5Uq53y0zex/wZuBd/vLgsVTKuZjoHwYvxn6f6oDnzKyGi8ipAjF1KTsdiJkZ0fby3e7++XG7NgPvi33+PuA/ZzrbeO7+KXevc/cGov9/j7v7u0m9nMeBo2a2PLbp9USnnk+pnESblq42s/zYz8Drid5/SrWcY86WazNws5nlmNlCouvF/CYJ+YAzi5f9OfBWdx8Ytytlcrr7S+5e7e4Nsd+nZmBt7Gd36jndXY8pPohOE7IPOAh8Otl5xuW6jugl5HbghdjjRqCCaG+R/bGP5cnOOi7za4EfxT5PuZzAZcDW2P/pfwBlKZrzb4E9wA7gm0BOKuQEvkv0vshI7M3rg+fKRbS55CCwF9iY5JwHiLbhj/0u3ZWKOSfsPwxUXmxOTbUhIiJxqYlJRETiUoEQEZG4VCBERCQuFQgREYlLBUJEROJSgRARkbhUIEREJK7/D2YO8DuBve+rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils import DisplayTokenLen\n",
    "DisplayTokenLen(df_train, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1224a-3d4f-490b-ba5c-6ba26788253b",
   "metadata": {
    "id": "56c1224a-3d4f-490b-ba5c-6ba26788253b",
    "tags": []
   },
   "source": [
    "### 2.2 Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910749fc-3ea3-4890-9b33-63a372dac9c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "910749fc-3ea3-4890-9b33-63a372dac9c1",
    "outputId": "938e976d-88cf-419c-d542-653b99c4477d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   558,  1302,  9412,   107,    78,   182,    59, 11685,  2179,\n",
       "          2959,   353,    96,  1302,  9412,    94,    43,    30,   878,   445,\n",
       "           232,   396,    60,  3941,    68,   379,  1724,  7660,    94,    43,\n",
       "            59, 11685,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "test_text = \"máy sài 3 tháng rồi rất ok pin trâu khỏi nói sài cả ngày đến tối 12 giờ đêm mới sạc mình chơi game liên_quân cả ngày rất ok\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text, \n",
    "                                  add_special_tokens = True,\n",
    "                                  max_length = 128,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\", \n",
    "                                  return_attention_mask = True, \n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41525acd-e406-4151-8dac-cfe8a0f0b18f",
   "metadata": {
    "id": "41525acd-e406-4151-8dac-cfe8a0f0b18f"
   },
   "source": [
    "### 2.3 Transform dataset for Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48afd56c-0825-4c12-9a15-ed0f35fa47ee",
   "metadata": {
    "id": "48afd56c-0825-4c12-9a15-ed0f35fa47ee"
   },
   "outputs": [],
   "source": [
    "from src.utils import GetNewLabels\n",
    "from src.conf import AbsaConfig\n",
    "from src.model import CustomDataset\n",
    "conf = AbsaConfig()\n",
    "target_list = GetNewLabels()\n",
    "MAX_LEN = conf.MAX_LEN\n",
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba170d82-daff-46bf-b143-db2aacbfbb54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba170d82-daff-46bf-b143-db2aacbfbb54",
    "outputId": "cd85a96c-7ac5-4585-87df-8fcdf455c253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,    60,   188,   558,    23,    35, 44553,  3385,  3385,  2662,\n",
       "         33640,   841, 11685,  5967,  2959,   690,   284,   258,  3998,   523,\n",
       "           889,   537,  2303,  3961,  3455,  1575,   726,  4097,   164,    15,\n",
       "         11535,   650,  1408,  3857,     2,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.]),\n",
       " 'comment': 'mới mua máy này tại thegioididong thốt_nốt cảm_thấy ok bin trâu chụp ảnh đẹp loa nghe to bắt wf khoẻ sóng ổn_định giá_thành vừa với túi_tiền nhân_viên tư_vấn nhiệt_tình'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the dataset\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c87017-2fbd-432e-a97d-fbcedc1b89ad",
   "metadata": {
    "id": "f0c87017-2fbd-432e-a97d-fbcedc1b89ad"
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "    batch_size=conf.TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "    batch_size=conf.VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "    batch_size=conf.TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b9491-5771-4888-9a6f-7fecb80e4e21",
   "metadata": {
    "id": "4f2b9491-5771-4888-9a6f-7fecb80e4e21"
   },
   "source": [
    "## 3. Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ae7823-0df5-44cf-a1fc-86aa28c7e927",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8ae7823-0df5-44cf-a1fc-86aa28c7e927",
    "outputId": "b680383b-e242-4ed6-d104-a5a5ac9289a1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5317941458fb43eeb8a1906a723ef2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model import BERTClass\n",
    "\n",
    "model = BERTClass()\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "model.to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433ff1c5-bb74-4d16-b612-31e2fae427a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "433ff1c5-bb74-4d16-b612-31e2fae427a7",
    "outputId": "7b3aa236-65e8-4578-bbdc-2657690668d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07eb4e4-3910-48bd-90fd-55027c4398fd",
   "metadata": {
    "id": "a07eb4e4-3910-48bd-90fd-55027c4398fd"
   },
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16cfa27f-a55f-4452-9df8-bcd8782f1c9a",
   "metadata": {
    "id": "16cfa27f-a55f-4452-9df8-bcd8782f1c9a"
   },
   "outputs": [],
   "source": [
    "from src.utils import SupportModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e9246b0-e1f8-4e68-a628-d8674dda917c",
   "metadata": {
    "id": "4e9246b0-e1f8-4e68-a628-d8674dda917c"
   },
   "outputs": [],
   "source": [
    "ModelSupporter = SupportModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a9367a7-c201-4810-9613-7c3751a05e2d",
   "metadata": {
    "id": "5a9367a7-c201-4810-9613-7c3751a05e2d"
   },
   "outputs": [],
   "source": [
    "# history = defaultdict(list)\n",
    "# best_accuracy = 0\n",
    "# EPOCHS = conf.EPOCHS\n",
    "# data_dir = conf.data_dir\n",
    "# for epoch in range(1, EPOCHS+1):\n",
    "#     print(f'Epoch {epoch}/{EPOCHS}')\n",
    "#     model, train_acc, train_loss = ModelSupporter.train_model(train_data_loader, model, optimizer)\n",
    "#     val_acc, val_loss = ModelSupporter.eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "#     print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "#     history['train_acc'].append(train_acc)\n",
    "#     history['train_loss'].append(train_loss)\n",
    "#     history['val_acc'].append(val_acc)\n",
    "#     history['val_loss'].append(val_loss)\n",
    "#     # save the best model\n",
    "#     if val_acc > best_accuracy:\n",
    "#         torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"MLTC_model_state.bin\"))\n",
    "#         best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99324af5-83a1-4558-9f8c-3a90594ef9aa",
   "metadata": {
    "id": "99324af5-83a1-4558-9f8c-3a90594ef9aa"
   },
   "outputs": [],
   "source": [
    "# PlotTrainingHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ea380-c554-4a9f-ba1b-ad703771343e",
   "metadata": {
    "id": "d09ea380-c554-4a9f-ba1b-ad703771343e"
   },
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5K-J8hMZC2wB",
   "metadata": {
    "id": "5K-J8hMZC2wB"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2acf6c3-31f4-4085-b35e-a4846c051190",
   "metadata": {
    "id": "f2acf6c3-31f4-4085-b35e-a4846c051190"
   },
   "outputs": [],
   "source": [
    "# # Loading pretrained model (best model)\n",
    "# model = BERTClass()\n",
    "# model.load_state_dict(torch.load(os.path.join(data_dir,\"output\",\"MLTC_model_state.bin\")))\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c99f1d3-0925-40d7-a4be-38b1ff2a8d50",
   "metadata": {
    "id": "9c99f1d3-0925-40d7-a4be-38b1ff2a8d50"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "# test_acc, test_loss = eval_model(test_data_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "098d168b-7f36-49c5-9ec4-6caca9c1e814",
   "metadata": {
    "id": "098d168b-7f36-49c5-9ec4-6caca9c1e814"
   },
   "outputs": [],
   "source": [
    "# The accuracy looks OK, similar to the validation accuracy\n",
    "# The model generalizes well !\n",
    "# test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7f78d34-0a93-4caf-8972-d16ee5906070",
   "metadata": {
    "id": "b7f78d34-0a93-4caf-8972-d16ee5906070"
   },
   "outputs": [],
   "source": [
    "# comments, predictions, prediction_probs, target_values = ModelSupporter.get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1a44aa5-64f9-4f38-a32e-f1683c03921e",
   "metadata": {
    "id": "c1a44aa5-64f9-4f38-a32e-f1683c03921e"
   },
   "outputs": [],
   "source": [
    "# print(f\"comments:{len(comments)} \\npredictions:{predictions.shape} \\nprediction_probs:{prediction_probs.shape} \\ntarget_values:{target_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8044f41d-ccfc-48b7-a79d-46ee45b51e58",
   "metadata": {
    "id": "8044f41d-ccfc-48b7-a79d-46ee45b51e58"
   },
   "outputs": [],
   "source": [
    "# # Generate Classification Metrics\n",
    "# # note that the total support is greater than the number of samples\n",
    "# # some samples have multiple lables\n",
    "\n",
    "# print(classification_report(target_values, predictions, target_names=target_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b06b9-4e8f-4592-9831-81f29c7ad821",
   "metadata": {
    "id": "377b06b9-4e8f-4592-9831-81f29c7ad821"
   },
   "source": [
    "## 6. Predict Raw Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43d62498-eac0-4eec-8fc3-0e04b27a21f5",
   "metadata": {
    "id": "43d62498-eac0-4eec-8fc3-0e04b27a21f5"
   },
   "outputs": [],
   "source": [
    "# ModelSupporter.predict_raw_text(model, tokenizer, raw_text='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76ea09-8134-4631-87d0-a3ea85842a61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.BigDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8611cc2-e186-4572-a1ef-1ff629c32b3f",
   "metadata": {},
   "source": [
    "### 7.1  Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a92ed-67a1-4bb2-abe7-131038675f57",
   "metadata": {},
   "source": [
    "Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea809872-2549-4756-86c2-748c71320f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install jdk8\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "import os\n",
    "# Set environment variable JAVA_HOME.\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e683bdf-9b95-4a39-986c-25c3247af2e2",
   "metadata": {},
   "source": [
    "Python 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6fdfa9-001f-4e2e-b39c-a0f8eaef0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Set current python version\n",
    "python_version = f\"3.8\"\n",
    "!wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
    "\n",
    "# Update Conda\n",
    "!conda install --channel defaults conda python=$python_version --yes\n",
    "!conda update --channel defaults --all --yes\n",
    "\n",
    "# Append to the sys.path\n",
    "_ = (sys.path\n",
    "        .append(f\"/usr/local/lib/python3.7/site-packages\"))\n",
    "\n",
    "os.environ['PYTHONHOME']=\"/usr/local\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07a671-05fb-4261-b551-0482648f2aef",
   "metadata": {},
   "source": [
    "### 7.2 BigDL dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37ee3d-35b9-4179-b745-90a92a128b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bigdl-orca\n",
    "!pip install six cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86875013-6687-4def-ab08-bcf5be126366",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install jep==3.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd5de3-3efc-4994-97b2-13eaa3de7208",
   "metadata": {},
   "source": [
    "### 7.3 Init Orca Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4bd62ae-cd8b-4a08-87a1-cc6acbfaa83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9151a-71ea-44dd-ad8a-18d8a1633286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.orca import init_orca_context, stop_orca_context\n",
    "\n",
    "cluster_mode = \"local\"\n",
    "if cluster_mode == \"local\":  # For local machine\n",
    "    init_orca_context(cores=2, memory=\"4g\")\n",
    "elif cluster_mode == \"k8s\":  # For K8s cluster\n",
    "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=2, memory=\"10g\", driver_memory=\"10g\", driver_cores=1)\n",
    "elif cluster_mode == \"yarn\":  # For Hadoop/YARN cluster\n",
    "    init_orca_context(\n",
    "    cluster_mode=\"yarn\", cores=2, num_nodes=2, memory=\"10g\",\n",
    "    driver_memory=\"10g\", driver_cores=1,\n",
    "    conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
    "        \"spark.task.maxFailures\": \"1\",\n",
    "        \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434e4bf-18ec-475a-93a4-74d850f6f9c7",
   "metadata": {},
   "source": [
    "### 7.4 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e2815-2bff-4a64-b117-5111dd781cdb",
   "metadata": {},
   "source": [
    "#### 7.4.1 Convert Pytorch Model to BigDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb3260-c81f-4e29-bc91-dbd7229df26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.orca.learn.pytorch import Estimator \n",
    "from bigdl.orca.learn.metrics import Accuracy\n",
    "from bigdl.orca.learn.pytorch.pytorch_spark_estimator import PyTorchSparkEstimator\n",
    "model.train()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "est = PyTorchSparkEstimator(model=model,\n",
    "                           optimizer=optimizer,\n",
    "                           loss=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659cb859-c845-40a6-b111-16b04046578a",
   "metadata": {},
   "source": [
    "#### 7.4.2 Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7819538-c117-4a32-afc7-590dccfc1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.orca.learn.trigger import EveryEpoch \n",
    "\n",
    "est.fit(data=train_data_loader, epochs=10, validation_data=val_data_loader,\n",
    "        checkpoint_trigger=EveryEpoch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781a0da-423f-43e5-ad41-54a6d0e4b57f",
   "metadata": {},
   "source": [
    "#### 7.4.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750c8c9-a159-480a-8f29-23e7090fab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = est.evaluate(data=test_data_loader, batch_size=conf.TEST_BATCH_SIZE)\n",
    "for r in result:\n",
    "    print(r, \":\", result[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a80c1-4768-475c-8cb2-563c9c4b3739",
   "metadata": {},
   "source": [
    "#### 7.4.5 Stop orca context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7eaee3-8aad-4ab5-9529-3919f069fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop orca context when program finishes\n",
    "stop_orca_context()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nTwn9pCetyVE",
    "0c499781-e2eb-400f-b076-0d6a691fa2cc",
    "56c1224a-3d4f-490b-ba5c-6ba26788253b",
    "41525acd-e406-4151-8dac-cfe8a0f0b18f"
   ],
   "name": "BigDataABSl.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
