{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96adbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926614ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff283a2-97b5-4a0d-b497-0db407340da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init('/home/henry/spark-3.3.0-bin-hadoop3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92d3c8f-4601-46b1-a15d-59a7d0788f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/henry/anaconda3/envs/BigData/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/henry/anaconda3/envs/BigData/lib/python3.8/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec0531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff242341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/10 03:01:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bac00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/lib/python3.9/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ssc = StreamingContext(sc, 10 )\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49756995",
   "metadata": {},
   "outputs": [],
   "source": [
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba44718",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = socket_stream.window(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabdec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "fields = (\"tag\", \"count\")\n",
    "Comment = namedtuple('Comment', fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902bc28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ee95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(60)\n",
    "# Use Parenthesis for multiple lines or use \\.\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  .filter( lambda word: 'bphone' in word.lower() ) # Checks for hashtag calls\n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) # Reduces\n",
    "  .map( lambda rec: Comment( rec[0], rec[1] ) ) # Stores in a Tweet Object\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") ) # Sorts Them in a DF\n",
    "  .limit(10).registerTempTable(\"Comments\") ) ) # Registers to a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601dca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee645ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while count < 10:\n",
    "    time.sleep(120)\n",
    "    try:\n",
    "        top_10_tweets = sqlContext.sql( 'Select tag, count from Comments' )\n",
    "        top_10_df = top_10_tweets.toPandas()\n",
    "        display.clear_output(wait=True)\n",
    "        plt.figure( figsize = ( 10, 8 ) )\n",
    "        sns.barplot( x=\"count\", y=\"tag\", data=top_10_df)\n",
    "        plt.show()\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "        print('Waiting')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c7ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
