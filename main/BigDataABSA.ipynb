{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "06098efd-425b-429e-8912-180d1fc60835",
      "metadata": {
        "id": "06098efd-425b-429e-8912-180d1fc60835",
        "outputId": "7f45ff1d-973b-4f4e-9a12-ef359bdbd501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 13 00:35:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hoanshiro/Smartphone-ABSA"
      ],
      "metadata": {
        "id": "4oydC3D8rQsS",
        "outputId": "39d51e1d-ca27-4229-bfd1-d73f7f9a8f83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4oydC3D8rQsS",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Smartphone-ABSA' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Smartphone-ABSA"
      ],
      "metadata": {
        "id": "e1-HAoc-rT8Y",
        "outputId": "52fc16e8-fb26-4a85-a832-5ba993b4af3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e1-HAoc-rT8Y",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Smartphone-ABSA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "G7ffC-WysQ1G",
        "outputId": "9e44c86f-2636-4662-b591-5a32b9acf002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "G7ffC-WysQ1G",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "zrbkNEQ5r4Aw",
        "outputId": "631351c1-ad25-4b0b-e43f-5c1e933e086e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zrbkNEQ5r4Aw",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Smartphone-ABSA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9cc541-cec0-4151-ba08-ec788ba89798",
      "metadata": {
        "id": "eb9cc541-cec0-4151-ba08-ec788ba89798"
      },
      "source": [
        "## 1. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c30aaf24-4bd3-4018-aad8-f1ea4fd9c7be",
      "metadata": {
        "id": "c30aaf24-4bd3-4018-aad8-f1ea4fd9c7be"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import sys\n",
        "import tqdm.notebook as tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 User Define"
      ],
      "metadata": {
        "id": "nTwn9pCetyVE"
      },
      "id": "nTwn9pCetyVE"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a5b2dabc-e6a7-4f82-a710-4f79724390fe",
      "metadata": {
        "id": "a5b2dabc-e6a7-4f82-a710-4f79724390fe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class AbsaConfig():\n",
        "    def __init__(self):\n",
        "        self.rdrsegmenter_path = 'VnCoreNLP/VnCoreNLP-1.1.1.jar'\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "        # Hyperparameters\n",
        "        self.mode_path = 'vinai/phobert-base'\n",
        "        self.MAX_LEN = 128\n",
        "        self.TRAIN_BATCH_SIZE = 32\n",
        "        self.VALID_BATCH_SIZE = 32\n",
        "        self.TEST_BATCH_SIZE = 32\n",
        "        self.EPOCHS = 10\n",
        "        self.LEARNING_RATE = 1e-05\n",
        "        self.THRESHOLD = 0.5  # threshold for the sigmoid\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3df7cec0-aba1-4bf3-b7ee-8c8415a74b89",
      "metadata": {
        "id": "3df7cec0-aba1-4bf3-b7ee-8c8415a74b89"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AdamW\n",
        "from vncorenlp import VnCoreNLP\n",
        "from emoji import replace_emoji\n",
        "# from conf import AbsaConfig\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import tqdm.notebook as tq\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf = AbsaConfig()\n",
        "\n",
        "\n",
        "def display_all_dataframe():\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.expand_frame_repr', False)\n",
        "    pd.set_option('max_colwidth', -1)\n",
        "\n",
        "\n",
        "def GetNewLabels():\n",
        "    aspects = ['SCREEN', 'CAMERA', 'FEATURES', 'BATTERY', 'PERFORMANCE', 'STORAGE', 'DESIGN', 'PRICE', 'GENERAL',\n",
        "               'SER&ACC']\n",
        "    polarities = ['Positive', 'Neutral', 'Negative']\n",
        "    new_labels = [f\"{aspect}#{polarity}\" for aspect in aspects for polarity in polarities]\n",
        "    return new_labels\n",
        "\n",
        "\n",
        "def GetStopWords():\n",
        "    df_stopwords = pd.read_csv(\n",
        "        'https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords-dash.txt',\n",
        "        sep='\\n', header=None, names=['stopwords'])\n",
        "    stop_words = set(df_stopwords.stopwords.values)\n",
        "    return stop_words\n",
        "\n",
        "\n",
        "def labels2onehot(row, raw_label='label'):\n",
        "    list_labels = row[raw_label].split(';')[:-1]\n",
        "    list_processed_labels = [re.sub('[{}]', '', label) for label in list_labels]\n",
        "    for label in list_processed_labels:\n",
        "        row[label] = 1\n",
        "    return row\n",
        "\n",
        "\n",
        "def DisplayTokenLen(df, tokenizer):\n",
        "    token_lens = []\n",
        "    for txt in tqdm(df.tokenize):\n",
        "        tokens = tokenizer.encode(txt, max_length=128)\n",
        "        token_lens.append(len(tokens))\n",
        "\n",
        "    sns.distplot(token_lens)\n",
        "\n",
        "\n",
        "def PlotTrainingHistory(history):\n",
        "    plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
        "    plt.plot(history['train_acc'], label='train accuracy')\n",
        "    plt.plot(history['val_acc'], label='validation accuracy')\n",
        "    plt.title('Training history')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    plt.ylim([0, 1])\n",
        "    plt.grid()\n",
        "\n",
        "\n",
        "class TextProcessing:\n",
        "    def __init__(self):\n",
        "        self.rdrsegmenter = VnCoreNLP(conf.rdrsegmenter_path, annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "\n",
        "    def ViTokenize(self, text, remove_stopwords=True):\n",
        "        list_tokens = self.rdrsegmenter.tokenize(text)\n",
        "        if remove_stopwords:\n",
        "            stop_words = GetStopWords()\n",
        "            list_tokens = [text for text in list_tokens[0] if text not in stop_words]\n",
        "        else:\n",
        "            list_tokens = list_tokens[0]\n",
        "        tokenized_text = ' '.join(list_tokens)\n",
        "        return tokenized_text\n",
        "\n",
        "    def clean_text(self, text, remove_stopwords=True):\n",
        "        # Lower\n",
        "        text = text.lower()\n",
        "        # Remove all emoji\n",
        "        text = replace_emoji(text, replace='')\n",
        "        # Remove all special char\n",
        "        special_chars = r\"[\\\"#$%&'()*+,.\\-\\/\\\\:;<=>@[\\]^_`{|}~\\n\\r\\t]\"\n",
        "        text = re.sub(special_chars, \" \", text)\n",
        "        # Vietnamese tokenize\n",
        "        text = self.ViTokenize(text, remove_stopwords)\n",
        "        return text\n",
        "\n",
        "\n",
        "class SupportModel:\n",
        "    def __init__(self):\n",
        "        self.device = conf.device\n",
        "\n",
        "    def loss_fn(self, outputs, targets):\n",
        "        return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "    def train_model(self, training_loader, model, optimizer):\n",
        "        losses = []\n",
        "        correct_predictions = 0\n",
        "        num_samples = 0\n",
        "        # set model to training mode (activate droput, batch norm)\n",
        "        model.train()\n",
        "        # initialize the progress bar\n",
        "        loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
        "                       leave=True, colour='steelblue')\n",
        "        for batch_idx, data in loop:\n",
        "            ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
        "            mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(self.device, dtype=torch.long)\n",
        "            targets = data['targets'].to(self.device, dtype=torch.float)\n",
        "\n",
        "            # forward\n",
        "            outputs = model(ids, mask, token_type_ids)  # (batch,predict)=(32,8)\n",
        "            loss = self.loss_fn(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "            # training accuracy, apply sigmoid, round (apply thresh 0.5)\n",
        "            outputs = torch.sigmoid(outputs).cpu().detach().numpy().round()\n",
        "            targets = targets.cpu().detach().numpy()\n",
        "            correct_predictions += np.sum(outputs == targets)\n",
        "            num_samples += targets.size  # total number of elements in the 2D array\n",
        "\n",
        "            # backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            # grad descent step\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            # loop.set_description(f\"\")\n",
        "            # loop.set_postfix(batch_loss=loss)\n",
        "\n",
        "        # returning: trained model, model accuracy, mean loss\n",
        "        return model, float(correct_predictions) / num_samples, np.mean(losses)\n",
        "\n",
        "    def eval_model(self, validation_loader, model):\n",
        "        losses = []\n",
        "        correct_predictions = 0\n",
        "        num_samples = 0\n",
        "        # set model to eval mode (turn off dropout, fix batch norm)\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, data in enumerate(validation_loader, 0):\n",
        "                ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
        "                mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
        "                token_type_ids = data['token_type_ids'].to(self.device, dtype=torch.long)\n",
        "                targets = data['targets'].to(self.device, dtype=torch.float)\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "                loss = self.loss_fn(outputs, targets)\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # validation accuracy\n",
        "                # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
        "                outputs = torch.sigmoid(outputs).cpu().detach().numpy().round()\n",
        "                targets = targets.cpu().detach().numpy()\n",
        "                correct_predictions += np.sum(outputs == targets)\n",
        "                num_samples += targets.size  # total number of elements in the 2D array\n",
        "\n",
        "        return float(correct_predictions) / num_samples, np.mean(losses)\n",
        "\n",
        "    def get_predictions(self, model, data_loader):\n",
        "        \"\"\"\n",
        "        Outputs:\n",
        "          predictions -\n",
        "        \"\"\"\n",
        "        model = model.eval()\n",
        "\n",
        "        comments = []\n",
        "        predictions = []\n",
        "        prediction_probs = []\n",
        "        target_values = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in data_loader:\n",
        "                comment = data[\"comment\"]\n",
        "                ids = data[\"input_ids\"].to(self.device, dtype=torch.long)\n",
        "                mask = data[\"attention_mask\"].to(self.device, dtype=torch.long)\n",
        "                token_type_ids = data['token_type_ids'].to(self.device, dtype=torch.long)\n",
        "                targets = data[\"targets\"].to(self.device, dtype=torch.float)\n",
        "\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "                # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
        "                outputs = torch.sigmoid(outputs).detach().cpu()\n",
        "                # thresholding at 0.5\n",
        "                preds = outputs.round()\n",
        "                targets = targets.detach().cpu()\n",
        "\n",
        "                comments.extend(comment)\n",
        "                predictions.extend(preds)\n",
        "                prediction_probs.extend(outputs)\n",
        "                target_values.extend(targets)\n",
        "\n",
        "        predictions = torch.stack(predictions)\n",
        "        prediction_probs = torch.stack(prediction_probs)\n",
        "        target_values = torch.stack(target_values)\n",
        "\n",
        "        return comments, predictions, prediction_probs, target_values\n",
        "\n",
        "    def predict_raw_text(self, model, tokenizer, raw_text):\n",
        "        cleaned_text = TextProcessing.clean_text(raw_text, remove_stopwords=False)\n",
        "        #\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            cleaned_text, max_length=conf.MAX_LEN, add_special_tokens=True,\n",
        "            return_token_type_ids=True, pad_to_max_length=True,\n",
        "            return_attention_mask=True, return_tensors='pt',\n",
        "        )\n",
        "        #\n",
        "        input_ids = encoded_text['input_ids'].to(self.device)\n",
        "        attention_mask = encoded_text['attention_mask'].to(self.device)\n",
        "        token_type_ids = encoded_text['token_type_ids'].to(self.device)\n",
        "        output = model(input_ids, attention_mask, token_type_ids)\n",
        "        # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
        "        output = torch.sigmoid(output).detach().cpu()\n",
        "        # thresholding at 0.5\n",
        "        output = output.flatten().round().numpy()\n",
        "\n",
        "        # Correctly identified the topic of the paper: High energy physics\n",
        "        print(f\"Comment: {raw_text}\")\n",
        "        target_list = GetNewLabels()\n",
        "        for idx, p in enumerate(output):\n",
        "            if p == 1:\n",
        "                print(f\"Label: {target_list[idx]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "# from conf import AbsaConfig\n",
        "# from utils import GetNewLabels\n",
        "\n",
        "\n",
        "conf = AbsaConfig()\n",
        "tokenizer = AutoTokenizer.from_pretrained(conf.mode_path)\n",
        "\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len, target_list):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.comment = list(df['tokenize'])\n",
        "        self.targets = self.df[target_list].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment = str(self.comment[index])\n",
        "        comment = \" \".join(comment.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index]),\n",
        "            'comment': comment\n",
        "        }\n",
        "\n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = AutoModel.from_pretrained('vinai/phobert-base', return_dict=True)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, len(GetNewLabels()))\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "2WcnVNCcuXY9",
        "outputId": "ee166071-968c-4c6d-d814-68d712126dc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2WcnVNCcuXY9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "578fd62d-ec73-44e4-8da2-d94faba52261",
      "metadata": {
        "id": "578fd62d-ec73-44e4-8da2-d94faba52261"
      },
      "source": [
        "## 2. Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "# display_all_dataframe()\n",
        "\n",
        "# os.system('git clone https://github.com/vncorenlp/VnCoreNLP.git')\n",
        "# os.system('wget -q https://github.com/LuongPhan/UIT-ViSFD/raw/main/UIT-ViSFD.zip -P data/')\n",
        "# os.system('unzip data/UIT-ViSFD.zip -d data')\n",
        "\n",
        "# TextProcessing = TextProcessing()\n",
        "\n",
        "# ls_df = []\n",
        "# new_labels = GetNewLabels()\n",
        "# for data_name in tqdm(['Train', 'Dev', 'Test']):\n",
        "#     df = pd.read_csv(f'data/{data_name}.csv')\n",
        "#     df = df[['comment', 'label']]\n",
        "\n",
        "#     for label in new_labels:\n",
        "#         df[label] = 0\n",
        "\n",
        "#     df = df.apply(lambda row: labels2onehot(row, raw_label='label'), axis=1) \n",
        "\n",
        "#     df['tokenize'] = df['comment'].apply(lambda text: TextProcessing.clean_text(text, remove_stopwords=False))\n",
        "#     # df['stop_words_remove'] = df['comment'].apply(lambda text: clean_text(text, remove_stopwords=True))\n",
        "\n",
        "#     df = df[['tokenize', *new_labels]]\n",
        "#     ls_df.append(df)\n",
        "\n",
        "# df_train, df_valid, df_test = ls_df\n",
        "\n",
        "# df_train.to_csv('data/processed_train.csv', index=False)\n",
        "# df_valid.to_csv('data/processed_valid.csv', index=False)\n",
        "# df_test.to_csv('data/processed_test.csv', index=False)\n"
      ],
      "metadata": {
        "id": "rdnCVWK44t_8"
      },
      "id": "rdnCVWK44t_8",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "120b06a4-405d-49bf-9328-0aa88471af20",
      "metadata": {
        "id": "120b06a4-405d-49bf-9328-0aa88471af20"
      },
      "source": [
        "### 2.1 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Smartphone-ABSA"
      ],
      "metadata": {
        "id": "GYBRcarZxVnk",
        "outputId": "b6d7b553-0f6e-4f75-af69-216ee671d368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GYBRcarZxVnk",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Smartphone-ABSA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "945a6679-ae0f-4e68-b89a-ab4c92234b98",
      "metadata": {
        "id": "945a6679-ae0f-4e68-b89a-ab4c92234b98"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('data/processed_train.csv')\n",
        "df_valid = pd.read_csv('data/processed_valid.csv')\n",
        "df_test = pd.read_csv('data/processed_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2a5d0a47-ac9d-4d30-b1a3-ccee35c9828c",
      "metadata": {
        "id": "2a5d0a47-ac9d-4d30-b1a3-ccee35c9828c",
        "outputId": "e13264e3-bf2e-48a8-bb1f-826651b17fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tokenize  SCREEN#Positive  \\\n",
              "7781  8g cái đi đánh là mạng giật giật ko chịu nổi c...                0   \n",
              "7782  mua dk giảm 500k mà lỗi lòi ra hết treo màn_hì...                0   \n",
              "7783  máy sài 3 tháng rồi rất ok pin trâu khỏi nói s...                0   \n",
              "7784  rất tiếc hàng realme ko có ốp lưng ngoài nên k...                0   \n",
              "7785  mình rất thất_vọng khi mua máy này bắt wifi cự...                0   \n",
              "\n",
              "      SCREEN#Neutral  SCREEN#Negative  CAMERA#Positive  CAMERA#Neutral  \\\n",
              "7781               0                0                0               0   \n",
              "7782               0                0                0               0   \n",
              "7783               0                0                0               0   \n",
              "7784               0                0                0               0   \n",
              "7785               0                0                0               0   \n",
              "\n",
              "      CAMERA#Negative  FEATURES#Positive  FEATURES#Neutral  FEATURES#Negative  \\\n",
              "7781                0                  0                 0                  1   \n",
              "7782                0                  0                 0                  1   \n",
              "7783                0                  0                 0                  0   \n",
              "7784                0                  0                 0                  0   \n",
              "7785                0                  0                 0                  1   \n",
              "\n",
              "      ...  DESIGN#Negative  PRICE#Positive  PRICE#Neutral  PRICE#Negative  \\\n",
              "7781  ...                0               0              0               0   \n",
              "7782  ...                0               1              0               0   \n",
              "7783  ...                0               0              0               0   \n",
              "7784  ...                0               0              0               1   \n",
              "7785  ...                0               0              0               0   \n",
              "\n",
              "      GENERAL#Positive  GENERAL#Neutral  GENERAL#Negative  SER&ACC#Positive  \\\n",
              "7781                 0                0                 0                 0   \n",
              "7782                 0                0                 0                 0   \n",
              "7783                 1                0                 0                 0   \n",
              "7784                 1                0                 0                 0   \n",
              "7785                 0                0                 1                 0   \n",
              "\n",
              "      SER&ACC#Neutral  SER&ACC#Negative  \n",
              "7781                0                 0  \n",
              "7782                0                 0  \n",
              "7783                0                 0  \n",
              "7784                0                 1  \n",
              "7785                0                 1  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b68d608d-3636-4ab7-8c38-c554f4fb7ba5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenize</th>\n",
              "      <th>SCREEN#Positive</th>\n",
              "      <th>SCREEN#Neutral</th>\n",
              "      <th>SCREEN#Negative</th>\n",
              "      <th>CAMERA#Positive</th>\n",
              "      <th>CAMERA#Neutral</th>\n",
              "      <th>CAMERA#Negative</th>\n",
              "      <th>FEATURES#Positive</th>\n",
              "      <th>FEATURES#Neutral</th>\n",
              "      <th>FEATURES#Negative</th>\n",
              "      <th>...</th>\n",
              "      <th>DESIGN#Negative</th>\n",
              "      <th>PRICE#Positive</th>\n",
              "      <th>PRICE#Neutral</th>\n",
              "      <th>PRICE#Negative</th>\n",
              "      <th>GENERAL#Positive</th>\n",
              "      <th>GENERAL#Neutral</th>\n",
              "      <th>GENERAL#Negative</th>\n",
              "      <th>SER&amp;ACC#Positive</th>\n",
              "      <th>SER&amp;ACC#Neutral</th>\n",
              "      <th>SER&amp;ACC#Negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7781</th>\n",
              "      <td>8g cái đi đánh là mạng giật giật ko chịu nổi c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7782</th>\n",
              "      <td>mua dk giảm 500k mà lỗi lòi ra hết treo màn_hì...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7783</th>\n",
              "      <td>máy sài 3 tháng rồi rất ok pin trâu khỏi nói s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7784</th>\n",
              "      <td>rất tiếc hàng realme ko có ốp lưng ngoài nên k...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7785</th>\n",
              "      <td>mình rất thất_vọng khi mua máy này bắt wifi cự...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b68d608d-3636-4ab7-8c38-c554f4fb7ba5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b68d608d-3636-4ab7-8c38-c554f4fb7ba5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b68d608d-3636-4ab7-8c38-c554f4fb7ba5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_train.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c499781-e2eb-400f-b076-0d6a691fa2cc",
      "metadata": {
        "id": "0c499781-e2eb-400f-b076-0d6a691fa2cc"
      },
      "source": [
        "### 2.2 Select Max Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c26b7da4-09e6-433d-9f95-a54def0ac8fc",
      "metadata": {
        "id": "c26b7da4-09e6-433d-9f95-a54def0ac8fc",
        "outputId": "e488379a-06ce-4f11-a35a-78f8eff5c2b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "868dcc17-18c6-4f4e-9fcd-1768ad919091",
      "metadata": {
        "id": "868dcc17-18c6-4f4e-9fcd-1768ad919091",
        "outputId": "9559ee06-57d3-4a79-ca3e-c8f9ffd55ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7786 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 7786/7786 [00:03<00:00, 1995.64it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "DisplayTokenLen(df_train, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c1224a-3d4f-490b-ba5c-6ba26788253b",
      "metadata": {
        "tags": [],
        "id": "56c1224a-3d4f-490b-ba5c-6ba26788253b"
      },
      "source": [
        "### 2.3. Check Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "910749fc-3ea3-4890-9b33-63a372dac9c1",
      "metadata": {
        "id": "910749fc-3ea3-4890-9b33-63a372dac9c1",
        "outputId": "938e976d-88cf-419c-d542-653b99c4477d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0,   558,  1302,  9412,   107,    78,   182,    59, 11685,  2179,\n",
              "          2959,   353,    96,  1302,  9412,    94,    43,    30,   878,   445,\n",
              "           232,   396,    60,  3941,    68,   379,  1724,  7660,    94,    43,\n",
              "            59, 11685,     2,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Test the tokenizer\n",
        "test_text = \"máy sài 3 tháng rồi rất ok pin trâu khỏi nói sài cả ngày đến tối 12 giờ đêm mới sạc mình chơi game liên_quân cả ngày rất ok\"\n",
        "# generate encodings\n",
        "encodings = tokenizer.encode_plus(test_text, \n",
        "                                  add_special_tokens = True,\n",
        "                                  max_length = 128,\n",
        "                                  truncation = True,\n",
        "                                  padding = \"max_length\", \n",
        "                                  return_attention_mask = True, \n",
        "                                  return_tensors = \"pt\")\n",
        "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
        "encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41525acd-e406-4151-8dac-cfe8a0f0b18f",
      "metadata": {
        "id": "41525acd-e406-4151-8dac-cfe8a0f0b18f"
      },
      "source": [
        "### 2.3 Transform for Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "48afd56c-0825-4c12-9a15-ed0f35fa47ee",
      "metadata": {
        "id": "48afd56c-0825-4c12-9a15-ed0f35fa47ee"
      },
      "outputs": [],
      "source": [
        "target_list = GetNewLabels()\n",
        "MAX_LEN = conf.MAX_LEN\n",
        "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
        "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
        "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ba170d82-daff-46bf-b143-db2aacbfbb54",
      "metadata": {
        "id": "ba170d82-daff-46bf-b143-db2aacbfbb54",
        "outputId": "cd85a96c-7ac5-4585-87df-8fcdf455c253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'comment': 'mới mua máy này tại thegioididong thốt_nốt cảm_thấy ok bin trâu chụp ảnh đẹp loa nghe to bắt wf khoẻ sóng ổn_định giá_thành vừa với túi_tiền nhân_viên tư_vấn nhiệt_tình',\n",
              " 'input_ids': tensor([    0,    60,   188,   558,    23,    35, 44553,  3385,  3385,  2662,\n",
              "         33640,   841, 11685,  5967,  2959,   690,   284,   258,  3998,   523,\n",
              "           889,   537,  2303,  3961,  3455,  1575,   726,  4097,   164,    15,\n",
              "         11535,   650,  1408,  3857,     2,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " 'targets': tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# testing the dataset\n",
        "next(iter(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f0c87017-2fbd-432e-a97d-fbcedc1b89ad",
      "metadata": {
        "id": "f0c87017-2fbd-432e-a97d-fbcedc1b89ad"
      },
      "outputs": [],
      "source": [
        "# Data loaders\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "    batch_size=conf.TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
        "    batch_size=conf.VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, \n",
        "    batch_size=conf.TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f2b9491-5771-4888-9a6f-7fecb80e4e21",
      "metadata": {
        "id": "4f2b9491-5771-4888-9a6f-7fecb80e4e21"
      },
      "source": [
        "## 3. Model Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f8ae7823-0df5-44cf-a1fc-86aa28c7e927",
      "metadata": {
        "id": "f8ae7823-0df5-44cf-a1fc-86aa28c7e927",
        "outputId": "b680383b-e242-4ed6-d104-a5a5ac9289a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (bert_model): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# from src.model import BERTClass\n",
        "\n",
        "model = BERTClass()\n",
        "# # Freezing BERT layers: (tested, weaker convergence)\n",
        "# for param in model.bert_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "model.to(conf.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "433ff1c5-bb74-4d16-b612-31e2fae427a7",
      "metadata": {
        "id": "433ff1c5-bb74-4d16-b612-31e2fae427a7",
        "outputId": "7b3aa236-65e8-4578-bbdc-2657690668d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-5)         "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07eb4e4-3910-48bd-90fd-55027c4398fd",
      "metadata": {
        "id": "a07eb4e4-3910-48bd-90fd-55027c4398fd"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "16cfa27f-a55f-4452-9df8-bcd8782f1c9a",
      "metadata": {
        "id": "16cfa27f-a55f-4452-9df8-bcd8782f1c9a"
      },
      "outputs": [],
      "source": [
        "# from src.utils import SupportModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4e9246b0-e1f8-4e68-a628-d8674dda917c",
      "metadata": {
        "id": "4e9246b0-e1f8-4e68-a628-d8674dda917c"
      },
      "outputs": [],
      "source": [
        "SupportModel = SupportModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5a9367a7-c201-4810-9613-7c3751a05e2d",
      "metadata": {
        "id": "5a9367a7-c201-4810-9613-7c3751a05e2d"
      },
      "outputs": [],
      "source": [
        "# history = defaultdict(list)\n",
        "# best_accuracy = 0\n",
        "# EPOCHS = conf.EPOCHS\n",
        "# for epoch in range(1, EPOCHS+1):\n",
        "#     print(f'Epoch {epoch}/{EPOCHS}')\n",
        "#     model, train_acc, train_loss = SupportModel.train_model(train_data_loader, model, optimizer)\n",
        "#     val_acc, val_loss = SupportModel.eval_model(val_data_loader, model, optimizer)\n",
        "\n",
        "#     print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
        "\n",
        "#     history['train_acc'].append(train_acc)\n",
        "#     history['train_loss'].append(train_loss)\n",
        "#     history['val_acc'].append(val_acc)\n",
        "#     history['val_loss'].append(val_loss)\n",
        "#     # save the best model\n",
        "#     if val_acc > best_accuracy:\n",
        "#         torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"MLTC_model_state.bin\"))\n",
        "#         best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "99324af5-83a1-4558-9f8c-3a90594ef9aa",
      "metadata": {
        "id": "99324af5-83a1-4558-9f8c-3a90594ef9aa"
      },
      "outputs": [],
      "source": [
        "# PlotTrainingHistory(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09ea380-c554-4a9f-ba1b-ad703771343e",
      "metadata": {
        "id": "d09ea380-c554-4a9f-ba1b-ad703771343e"
      },
      "source": [
        "## 5. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5K-J8hMZC2wB"
      },
      "id": "5K-J8hMZC2wB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f2acf6c3-31f4-4085-b35e-a4846c051190",
      "metadata": {
        "id": "f2acf6c3-31f4-4085-b35e-a4846c051190"
      },
      "outputs": [],
      "source": [
        "# # Loading pretrained model (best model)\n",
        "# model = BERTClass()\n",
        "# model.load_state_dict(torch.load(os.path.join(data_dir,\"output\",\"MLTC_model_state.bin\")))\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9c99f1d3-0925-40d7-a4be-38b1ff2a8d50",
      "metadata": {
        "id": "9c99f1d3-0925-40d7-a4be-38b1ff2a8d50"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using the test data\n",
        "# test_acc, test_loss = eval_model(test_data_loader, model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "098d168b-7f36-49c5-9ec4-6caca9c1e814",
      "metadata": {
        "id": "098d168b-7f36-49c5-9ec4-6caca9c1e814"
      },
      "outputs": [],
      "source": [
        "# The accuracy looks OK, similar to the validation accuracy\n",
        "# The model generalizes well !\n",
        "# test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b7f78d34-0a93-4caf-8972-d16ee5906070",
      "metadata": {
        "id": "b7f78d34-0a93-4caf-8972-d16ee5906070"
      },
      "outputs": [],
      "source": [
        "# comments, predictions, prediction_probs, target_values = SupportModel.get_predictions(model, test_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c1a44aa5-64f9-4f38-a32e-f1683c03921e",
      "metadata": {
        "id": "c1a44aa5-64f9-4f38-a32e-f1683c03921e"
      },
      "outputs": [],
      "source": [
        "# print(f\"comments:{len(comments)} \\npredictions:{predictions.shape} \\nprediction_probs:{prediction_probs.shape} \\ntarget_values:{target_values.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "8044f41d-ccfc-48b7-a79d-46ee45b51e58",
      "metadata": {
        "id": "8044f41d-ccfc-48b7-a79d-46ee45b51e58"
      },
      "outputs": [],
      "source": [
        "# # Generate Classification Metrics\n",
        "# # note that the total support is greater than the number of samples\n",
        "# # some samples have multiple lables\n",
        "\n",
        "# print(classification_report(target_values, predictions, target_names=target_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377b06b9-4e8f-4592-9831-81f29c7ad821",
      "metadata": {
        "id": "377b06b9-4e8f-4592-9831-81f29c7ad821"
      },
      "source": [
        "## 6. Predict Raw Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "43d62498-eac0-4eec-8fc3-0e04b27a21f5",
      "metadata": {
        "id": "43d62498-eac0-4eec-8fc3-0e04b27a21f5"
      },
      "outputs": [],
      "source": [
        "# SupportModel.predict_raw_text(model, tokenizer, raw_text='')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. BigDL"
      ],
      "metadata": {
        "id": "IG-IdEv1vKwR"
      },
      "id": "IG-IdEv1vKwR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNTssjdw2Bpi"
      },
      "source": [
        "## **Environment Preparation**"
      ],
      "id": "tNTssjdw2Bpi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOosIv3t2Fhp"
      },
      "source": [
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
      ],
      "id": "fOosIv3t2Fhp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBs-RL5p2Ia2",
        "outputId": "78090d95-6922-4562-d3ae-25149490c54f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ],
      "id": "IBs-RL5p2Ia2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS20JSbY2LCJ"
      },
      "source": [
        "**Install Analytics Zoo**\n",
        "\n",
        " "
      ],
      "id": "wS20JSbY2LCJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C1GYEhGIlWu"
      },
      "source": [
        "[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) is needed to prepare the Python environment for running this example. \n",
        "\n",
        "**Note**: The following code cell is specific for setting up conda environment on Colab; for general conda installation, please refer to the [install guide](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) for more details."
      ],
      "id": "5C1GYEhGIlWu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDq-ahZfthT-"
      },
      "source": [
        "import sys\n",
        "\n",
        "# Set current python version\n",
        "python_version = f\"3.7.10\""
      ],
      "execution_count": 34,
      "outputs": [],
      "id": "uDq-ahZfthT-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wouustbSJS2r"
      },
      "source": [
        "# Install Miniconda\n",
        "# !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Update Conda\n",
        "!conda install --channel defaults conda python=$python_version --yes\n",
        "!conda update --channel defaults --all --yes\n",
        "\n",
        "# Append to the sys.path\n",
        "_ = (sys.path\n",
        "        .append(f\"/usr/local/lib/python3.7/site-packages\"))\n",
        "\n",
        "os.environ['PYTHONHOME']=\"/usr/local\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "wouustbSJS2r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LOrK0lQHhrh"
      },
      "source": [
        "You can install the latest pre-release version using `pip install --pre --upgrade analytics-zoo[ray]`."
      ],
      "id": "1LOrK0lQHhrh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8lgWGhG2Oij"
      },
      "source": [
        "# Install latest pre-release version of Analytics Zoo \n",
        "# Installing Analytics Zoo from pip will automatically install pyspark, bigdl, and their dependencies.\n",
        "!pip install --pre --upgrade analytics-zoo[ray]"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "A8lgWGhG2Oij"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latest pre-release version of BigDL Orca \n",
        "# Installing BigDL Orca from pip will automatically install pyspark, bigdl, and their dependencies.\n",
        "!pip install --pre --upgrade bigdl-orca\n",
        "!pip install jep==3.9.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rigWfxex706K",
        "outputId": "f1151257-ba55-44ec-efc3-e54ea58560b6"
      },
      "id": "rigWfxex706K",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bigdl-orca in /usr/local/lib/python3.7/site-packages (2.1.0b202207121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/site-packages (from bigdl-orca) (3.7.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/site-packages (from bigdl-orca) (23.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from bigdl-orca) (21.3)\n",
            "Requirement already satisfied: bigdl-tf==0.14.0.dev1 in /usr/local/lib/python3.7/site-packages (from bigdl-orca) (0.14.0.dev1)\n",
            "Requirement already satisfied: bigdl-math==0.14.0.dev1 in /usr/local/lib/python3.7/site-packages (from bigdl-orca) (0.14.0.dev1)\n",
            "Requirement already satisfied: bigdl-dllib==2.1.0b202207121 in /usr/local/lib/python3.7/site-packages (from bigdl-orca) (2.1.0b202207121)\n",
            "Requirement already satisfied: bigdl-core==2.1.0b20220321 in /usr/local/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b202207121->bigdl-orca) (2.1.0b20220321)\n",
            "Requirement already satisfied: conda-pack==0.3.1 in /usr/local/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b202207121->bigdl-orca) (0.3.1)\n",
            "Requirement already satisfied: pyspark==2.4.6 in /usr/local/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b202207121->bigdl-orca) (2.4.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b202207121->bigdl-orca) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b202207121->bigdl-orca) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from conda-pack==0.3.1->bigdl-dllib==2.1.0b202207121->bigdl-orca) (61.2.0)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.7/site-packages (from pyspark==2.4.6->bigdl-dllib==2.1.0b202207121->bigdl-orca) (0.10.7)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->bigdl-orca) (3.0.9)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jep==3.9.0 in /usr/local/lib/python3.7/site-packages (3.9.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EFkPl4I2RJG",
        "outputId": "3920a83a-4f37-45be-8ca4-18097ee7368f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install python dependencies\n",
        "!pip install torch==1.7.1 torchvision==0.8.2"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/site-packages (1.7.1)\n",
            "Requirement already satisfied: torchvision==0.8.2 in /usr/local/lib/python3.7/site-packages (0.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch==1.7.1) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/site-packages (from torchvision==0.8.2) (9.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "id": "3EFkPl4I2RJG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATJ4YPAS2TQm"
      },
      "source": [
        "## **Distributed PyTorch using Orca APIs**\n",
        "\n",
        "In this guide we will describe how to scale out PyTorch programs using `torch_distributed` package on Orca in 4 simple steps."
      ],
      "id": "ATJ4YPAS2TQm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXeY_v2S24bN"
      },
      "source": [
        "# import necesary libraries and modules\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from bigdl.orca import init_orca_context, stop_orca_context\n",
        "from bigdl.orca import OrcaContext"
      ],
      "execution_count": 39,
      "outputs": [],
      "id": "LXeY_v2S24bN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn6xcsq43FRQ"
      },
      "source": [
        "### **Step 1: Init Orca Context**"
      ],
      "id": "dn6xcsq43FRQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXMGhKPk3GYN",
        "outputId": "df07b4b5-1ec7-40e3-837a-367f2f16f96f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# recommended to set it to True when running BigDL in Jupyter notebook. \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":\n",
        "    init_orca_context(cores=1, memory=\"2g\") # run in local mode\n",
        "elif cluster_mode == \"k8s\":\n",
        "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
        "elif cluster_mode == \"yarn\":\n",
        "    init_orca_context(\n",
        "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
        "        driver_memory=\"10g\", driver_cores=1,\n",
        "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
        "              \"spark.task.maxFailures\": \"1\",\n",
        "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"}) # run on Hadoop YARN cluster"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n"
          ]
        }
      ],
      "id": "mXMGhKPk3GYN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbu_llz48oNL"
      },
      "source": [
        "This is the only place where you need to specify local or distributed mode. View [Orca Context](https://analytics-zoo.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html) for more details.\n",
        "\n",
        "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
      ],
      "id": "hbu_llz48oNL"
    },
    {
      "cell_type": "code",
      "source": [
        "# from zoo.orca.learn.pytorch import Estimator\n",
        "# from zoo.orca.learn.metrics import Accuracy\n",
        "\n",
        "# est = Estimator.from_torch(model=model, optimizer=optimizer, loss=torch.nn.BCELoss(), metrics=[Accuracy()])"
      ],
      "metadata": {
        "id": "JAiXZjKhvtXX"
      },
      "id": "JAiXZjKhvtXX",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Training"
      ],
      "metadata": {
        "id": "U763OjxVCgG2"
      },
      "id": "U763OjxVCgG2"
    },
    {
      "cell_type": "code",
      "source": [
        "from bigdl.orca.learn.pytorch import Estimator\n",
        "from bigdl.orca.learn.metrics import Accuracy\n",
        "\n",
        "est = Estimator.from_torch(model=model,\n",
        "                           optimizer=optimizer,\n",
        "                           loss=torch.nn.BCEWithLogitsLoss(),\n",
        "                           metrics=[Accuracy()])"
      ],
      "metadata": {
        "id": "Xm0udb91w_1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44302cd-833e-49bf-f957-7d20c96d7089"
      },
      "id": "Xm0udb91w_1m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating: createTorchLoss\n",
            "creating: createTorchOptim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bigdl.orca.learn.trigger import EveryEpoch \n",
        "\n",
        "\n",
        "est.fit(data=train_data_loader, epochs=1, validation_data=val_data_loader,\n",
        "        checkpoint_trigger=EveryEpoch())"
      ],
      "metadata": {
        "id": "P_yc3AteAQAd"
      },
      "id": "P_yc3AteAQAd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFQCQwH0UBF1"
      },
      "source": [
        "### Step 3: Evaluate"
      ],
      "id": "tFQCQwH0UBF1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3cUxgYwUCUl"
      },
      "source": [
        "result = est.evaluate(data=test_data_loader, batch_size=conf.TEST_BATCH_SIZE)\n",
        "for r in result:\n",
        "    print(r, \":\", result[r])"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "Z3cUxgYwUCUl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YASrq-VzXdpJ"
      },
      "source": [
        "The accuracy of this model has reached 98%."
      ],
      "id": "YASrq-VzXdpJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSSReIykRPIB"
      },
      "source": [
        "# stop orca context when program finishes\n",
        "stop_orca_context()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "uSSReIykRPIB"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "BigDataABSl.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nTwn9pCetyVE",
        "0c499781-e2eb-400f-b076-0d6a691fa2cc",
        "56c1224a-3d4f-490b-ba5c-6ba26788253b",
        "41525acd-e406-4151-8dac-cfe8a0f0b18f"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}