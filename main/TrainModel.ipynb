{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06098efd-425b-429e-8912-180d1fc60835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc541-cec0-4151-ba08-ec788ba89798",
   "metadata": {},
   "source": [
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f517314f-aaa8-467e-8033-20a869133ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/henry/Pictures/BigData_ABSA\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30aaf24-4bd3-4018-aad8-f1ea4fd9c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b2dabc-e6a7-4f82-a710-4f79724390fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df7cec0-aba1-4bf3-b7ee-8c8415a74b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578fd62d-ec73-44e4-8da2-d94faba52261",
   "metadata": {},
   "source": [
    "## 2. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b06a4-405d-49bf-9328-0aa88471af20",
   "metadata": {},
   "source": [
    "### 2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945a6679-ae0f-4e68-b89a-ab4c92234b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/processed_train.csv')\n",
    "df_valid = pd.read_csv('data/processed_valid.csv')\n",
    "df_test = pd.read_csv('data/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5d0a47-ac9d-4d30-b1a3-ccee35c9828c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenize</th>\n",
       "      <th>SCREEN#Positive</th>\n",
       "      <th>SCREEN#Neutral</th>\n",
       "      <th>SCREEN#Negative</th>\n",
       "      <th>CAMERA#Positive</th>\n",
       "      <th>CAMERA#Neutral</th>\n",
       "      <th>CAMERA#Negative</th>\n",
       "      <th>FEATURES#Positive</th>\n",
       "      <th>FEATURES#Neutral</th>\n",
       "      <th>FEATURES#Negative</th>\n",
       "      <th>...</th>\n",
       "      <th>DESIGN#Negative</th>\n",
       "      <th>PRICE#Positive</th>\n",
       "      <th>PRICE#Neutral</th>\n",
       "      <th>PRICE#Negative</th>\n",
       "      <th>GENERAL#Positive</th>\n",
       "      <th>GENERAL#Neutral</th>\n",
       "      <th>GENERAL#Negative</th>\n",
       "      <th>SER&amp;ACC#Positive</th>\n",
       "      <th>SER&amp;ACC#Neutral</th>\n",
       "      <th>SER&amp;ACC#Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>8g cái đi đánh là mạng giật giật ko chịu nổi c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>mua dk giảm 500k mà lỗi lòi ra hết treo màn_hì...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>máy sài 3 tháng rồi rất ok pin trâu khỏi nói s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>rất tiếc hàng realme ko có ốp lưng ngoài nên k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>mình rất thất_vọng khi mua máy này bắt wifi cự...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tokenize  SCREEN#Positive  \\\n",
       "7781  8g cái đi đánh là mạng giật giật ko chịu nổi c...                0   \n",
       "7782  mua dk giảm 500k mà lỗi lòi ra hết treo màn_hì...                0   \n",
       "7783  máy sài 3 tháng rồi rất ok pin trâu khỏi nói s...                0   \n",
       "7784  rất tiếc hàng realme ko có ốp lưng ngoài nên k...                0   \n",
       "7785  mình rất thất_vọng khi mua máy này bắt wifi cự...                0   \n",
       "\n",
       "      SCREEN#Neutral  SCREEN#Negative  CAMERA#Positive  CAMERA#Neutral  \\\n",
       "7781               0                0                0               0   \n",
       "7782               0                0                0               0   \n",
       "7783               0                0                0               0   \n",
       "7784               0                0                0               0   \n",
       "7785               0                0                0               0   \n",
       "\n",
       "      CAMERA#Negative  FEATURES#Positive  FEATURES#Neutral  FEATURES#Negative  \\\n",
       "7781                0                  0                 0                  1   \n",
       "7782                0                  0                 0                  1   \n",
       "7783                0                  0                 0                  0   \n",
       "7784                0                  0                 0                  0   \n",
       "7785                0                  0                 0                  1   \n",
       "\n",
       "      ...  DESIGN#Negative  PRICE#Positive  PRICE#Neutral  PRICE#Negative  \\\n",
       "7781  ...                0               0              0               0   \n",
       "7782  ...                0               1              0               0   \n",
       "7783  ...                0               0              0               0   \n",
       "7784  ...                0               0              0               1   \n",
       "7785  ...                0               0              0               0   \n",
       "\n",
       "      GENERAL#Positive  GENERAL#Neutral  GENERAL#Negative  SER&ACC#Positive  \\\n",
       "7781                 0                0                 0                 0   \n",
       "7782                 0                0                 0                 0   \n",
       "7783                 1                0                 0                 0   \n",
       "7784                 1                0                 0                 0   \n",
       "7785                 0                0                 1                 0   \n",
       "\n",
       "      SER&ACC#Neutral  SER&ACC#Negative  \n",
       "7781                0                 0  \n",
       "7782                0                 0  \n",
       "7783                0                 0  \n",
       "7784                0                 1  \n",
       "7785                0                 1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c499781-e2eb-400f-b076-0d6a691fa2cc",
   "metadata": {},
   "source": [
    "### 2.2 Select Max Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26b7da4-09e6-433d-9f95-a54def0ac8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868dcc17-18c6-4f4e-9fcd-1768ad919091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                          | 0/7786 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7786/7786 [00:01<00:00, 5352.80it/s]\n",
      "/home/henry/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DisplayTokenLen(df_train, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1224a-3d4f-490b-ba5c-6ba26788253b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3. Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910749fc-3ea3-4890-9b33-63a372dac9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   558,  1302,  9412,   107,    78,   182,    59, 11685,  2179,\n",
       "          2959,   353,    96,  1302,  9412,    94,    43,    30,   878,   445,\n",
       "           232,   396,    60,  3941,    68,   379,  1724,  7660,    94,    43,\n",
       "            59, 11685,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "test_text = \"máy sài 3 tháng rồi rất ok pin trâu khỏi nói sài cả ngày đến tối 12 giờ đêm mới sạc mình chơi game liên_quân cả ngày rất ok\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text, \n",
    "                                  add_special_tokens = True,\n",
    "                                  max_length = 128,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\", \n",
    "                                  return_attention_mask = True, \n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41525acd-e406-4151-8dac-cfe8a0f0b18f",
   "metadata": {},
   "source": [
    "### 2.3 Transform for Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc4459b-a2ce-4fff-a827-fbddcec7146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from src.model import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48afd56c-0825-4c12-9a15-ed0f35fa47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = GetNewLabels()\n",
    "MAX_LEN = conf.MAX_LEN\n",
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba170d82-daff-46bf-b143-db2aacbfbb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,    60,   188,   558,    23,    35, 44553,  3385,  3385,  2662,\n",
       "         33640,   841, 11685,  5967,  2959,   690,   284,   258,  3998,   523,\n",
       "           889,   537,  2303,  3961,  3455,  1575,   726,  4097,   164,    15,\n",
       "         11535,   650,  1408,  3857,     2,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.]),\n",
       " 'comment': 'mới mua máy này tại thegioididong thốt_nốt cảm_thấy ok bin trâu chụp ảnh đẹp loa nghe to bắt wf khoẻ sóng ổn_định giá_thành vừa với túi_tiền nhân_viên tư_vấn nhiệt_tình'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the dataset\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c87017-2fbd-432e-a97d-fbcedc1b89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "    batch_size=conf.TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "    batch_size=conf.VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "    batch_size=conf.TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b9491-5771-4888-9a6f-7fecb80e4e21",
   "metadata": {},
   "source": [
    "## 3. Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ae7823-0df5-44cf-a1fc-86aa28c7e927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model import BERTClass\n",
    "\n",
    "model = BERTClass()\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "model.to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433ff1c5-bb74-4d16-b612-31e2fae427a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07eb4e4-3910-48bd-90fd-55027c4398fd",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16cfa27f-a55f-4452-9df8-bcd8782f1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import SupportModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e9246b0-e1f8-4e68-a628-d8674dda917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportModel = SupportModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a9367a7-c201-4810-9613-7c3751a05e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21479277392742c696fb3323608bc2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     model, train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mSupportModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m SupportModel\u001b[38;5;241m.\u001b[39meval_model(val_data_loader, model, optimizer)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Pictures/BigData_ABSA/src/utils.py:130\u001b[0m, in \u001b[0;36mSupportModel.train_model\u001b[0;34m(self, training_loader, model, optimizer)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[1;32m    129\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 130\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# grad descent step\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "EPOCHS = conf.EPOCHS\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = SupportModel.train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = SupportModel.eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"MLTC_model_state.bin\"))\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99324af5-83a1-4558-9f8c-3a90594ef9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PlotTrainingHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ea380-c554-4a9f-ba1b-ad703771343e",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acf6c3-31f4-4085-b35e-a4846c051190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model (best model)\n",
    "model = BERTClass()\n",
    "model.load_state_dict(torch.load(os.path.join(data_dir,\"output\",\"MLTC_model_state.bin\")))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99f1d3-0925-40d7-a4be-38b1ff2a8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "test_acc, test_loss = eval_model(test_data_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d168b-7f36-49c5-9ec4-6caca9c1e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy looks OK, similar to the validation accuracy\n",
    "# The model generalizes well !\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f78d34-0a93-4caf-8972-d16ee5906070",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments, predictions, prediction_probs, target_values = SupportModel.get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a44aa5-64f9-4f38-a32e-f1683c03921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"comments:{len(comments)} \\npredictions:{predictions.shape} \\nprediction_probs:{prediction_probs.shape} \\ntarget_values:{target_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044f41d-ccfc-48b7-a79d-46ee45b51e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Classification Metrics\n",
    "# note that the total support is greater than the number of samples\n",
    "# some samples have multiple lables\n",
    "\n",
    "print(classification_report(target_values, predictions, target_names=target_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b06b9-4e8f-4592-9831-81f29c7ad821",
   "metadata": {},
   "source": [
    "## 6. Predict Raw Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d62498-eac0-4eec-8fc3-0e04b27a21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportModel.predict_raw_text(model, tokenizer, raw_text='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
